import torch
from transformers import T5Tokenizer, T5ForConditionalGeneration

# Load the pre-trained T5 model and tokenizer
tokenizer = T5Tokenizer.from_pretrained('t5-small')
model = T5ForConditionalGeneration.from_pretrained('t5-small')

# Function to generate AI notes (summary) from input text
def generate_notes(text, max_length=150):
    """
    Generate summarized AI notes from the given input text.

    Args:
    - text (str): The input content to summarize.
    - max_length (int): Maximum length of the generated summary.

    Returns:
    - summary (str): The AI-generated notes or summary.
    """
    # Add the "summarize:" prompt to the input for the T5 model
    input_text = "summarize: " + text
    
    # Tokenize the input text
    inputs = tokenizer(input_text, return_tensors="pt", max_length=512, truncation=True)
    
    # Generate summary using the model
    with torch.no_grad():
        summary_ids = model.generate(
            inputs['input_ids'], 
            max_length=max_length, 
            num_beams=4, 
            length_penalty=2.0, 
            early_stopping=True
        )
    
    # Decode the generated summary back into text
    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)
    return summary

# Main function to interact with the user
def main():
    print("AI Notes Generator\n")
    
    # Taking input from the user (long text for summarization)
    input_text = input("Enter the text you want to generate notes from: \n")
    
    # Generate AI notes from the provided input text
    notes = generate_notes(input_text)
    
    # Output the generated notes (summary)
    print("\nGenerated AI Notes:")
    print(notes)

# Run the main function if the script is executed
if __name__ == "__main__":
    main()
